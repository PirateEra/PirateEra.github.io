- title: "Pirate Era"
  date: "2019-Present"
  description: "Owner of an MMORPG built inside Minecraft"
  image: "/assets/images/projects/pirate-era/pirate-era-project.png"
  url: "/projects/pirate-era/"

- id: hightide
  date: "01-2017"
  title: "High Tide"
  description: "Co-Owner of a multiplayer survival game in Unity3D set in a medieval world."
  image: "/assets/images/hightide_cover.png"
  url: "/pages/projects/hightide"
  tools: "Unity3D | C# | Networking | MySQL | Multiplayer"
  about: |
    High Tide was a self-started online multiplayer survival game co-developed with a friend. Players built castles and competed on official servers. The world underwent server wipes triggered by an incoming tide, forcing naval combat during these events. The project spanned 18-24 months and was my first serious game project, where I gained deep experience in Unity3D, networking, and gameplay systems.
  media:
    - "https://www.youtube.com/watch?v=SvbI4OyGvQU"
    - "https://www.youtube.com/watch?v=vE84TJUep0Y"
    - "https://www.youtube.com/watch?v=6icDc453A_o"
    - "/assets/videos/hightidebuildsystem.mp4"
    - "/assets/videos/hightide_swimming.mp4"
    - "/assets/videos/hightide_fighting.mp4"
  contributions:
    Character Controller:
      - "Developed a 3D character controller capable of multiple stances: passive, fighting, weapon-specific stances, swimming."
      - "Implemented smooth stance switching and animation blending for gameplay fluidity."
    Building System:
      - "Created a modular building system using block shapes with smart snapping for correct materials."
      - "Enabled players to construct structures in the world, saving them persistently on the server."
    Networking & Multiplayer:
      - "Implemented client-server architecture to sync player actions, bases, and inventories using MySQL."
      - "Developed PVP mechanics allowing players to damage each other and interact dynamically in the world."

# - id: hightide
  # logo: "/assets/images/projects/mock/mockimg.png"
  # title: "High Tide"
  # description: "Co-Owner of a survival game made in Unity3D which sadly never launched"
  # image: "/assets/images/projects/mock/mockimg.png"
  # url: "/pages/projects/hightide"
  # tools: "Unity3D | C# | Two-man team"
  # about: "High Tide is a Unity3D surival game. It plays off in a medieval setting where players build castles and compete with each other on official servers"
  # project_pdf_title: "Report"
  # project_pdf: "/assets/pdfs/ATCS_Report.pdf"
  # presentation_title: "example title"
  # presentation_folder: "/assets/slides/ai4mi/"
  # media:
  #   - "https://www.youtube.com/watch?v=SvbI4OyGvQU"
  #   - "https://www.youtube.com/watch?v=vE84TJUep0Y"
  #   - "/assets/videos/hightidebuildsystem.mp4"
  #   - "/assets/videos/hightide_swimming.mp4"
  #   - "/assets/videos/hightide_fighting.mp4"
  # contributions:
  #   Character Controller:
  #     - "Implemented movement and camera system"
  #     - "Added sprinting and crouching mechanics"
  #   Animation Controller:
  #     - "Integrated state-based animation system"
  #     - "Synced animation transitions with gameplay logic"
  #   Building System:
  #     - "Created a modular building system"
  #     - "Allowed to create and build houses in a block based setting"
  # code_snippets_title: Code Samples
  # code_snippets:
  #   - title: "C# example"
  #     content: |
  #       ```csharp
  #       void Update() {
  #         if (Input.GetKey(KeyCode.Space)) Jump();
  #       }
  #       ```
  #   - title: "Python example"
  #     content: |
  #       ```python
  #       def example_code(speed):
  #           print(f"Moving at {speed} speed!")
  #       ```

- id: graphunderstanding
  date: "06-2025"
  title: "LLM Commentary for Graph Understanding"
  description: "Interactive graph visualization system to query graphs using natural language, providing LLM explanations and significance scores for query terms."
  tools: "Python | Dash | Plotly | Pandas | Ollama (Llama3.2:3b)"
  about: "The system proposes an interactive, user-friendly visual interface that extends the G-Retriever architecture, allowing users to retrieve graphs using natural language queries. It enhances interpretability by providing comprehensive explanations from the LLM and offering phrase-level feedback (significance scores) on how influential noun, verb, and preposition phrases were in generating the resulting subgraph."
  image: "/assets/images/graph_cover.png"
  url: "/pages/projects/graphunderstanding/"
  github-link: https://github.com/PirateEra/Multimedia-Analytics
  project_pdf_title: "Technical Report"
  project_pdf: "/assets/pdfs/graphunderstanding.pdf"
  contributions:
    Interactive Interface Development:
      - "Developed an interactive and user-friendly visual system for natural language graph querying using Dash and Plotly."
      - "Visualized the original graphs and their retrieved subgraphs in the interface's center part."
    Query Interpretability & Feedback:
      - "Implemented phrase-level feedback over the user's query by providing significance scores to show how relevant a phrase was for retrieving the subgraph."
      - "Integrated the significance score calculation using an entity-level perturbation strategy and the Jaccard similarity between the original and perturbed subgraphs."
    LLM Integration & Explanation:
      - "Utilized an LLM (Llama3.2:3b via Ollama) to answer user queries based on the retrieved subgraph."
      - "Provided an explanation alongside the generated answer, detailing how the LLM arrived at its conclusion."
    Data Analysis and Interpretation:
      - "Developed a novel method for phrase-level feedback by calculating significance scores for query terms to enhance model interpretability."
      - "Employed the Entity-level Perturbation strategy to modify queries and determine the influence of specific lexical units on subgraph retrieval."
      - "Quantified entity influence by calculating the similarity (using Jaccard index concept) between the original and perturbed subgraphs."
  presentation_title: "Visual Interface Screenshots"
  presentation_folder: "/assets/images/projects/graphvisualisation/"
  # media:
  #   - /assets/images/projects/graphvisualisation/2.png
  #   - /assets/images/projects/graphvisualisation/3.png
  #   - /assets/images/projects/graphvisualisation/1.png

- id: "ood-generalization"
  title: "ACTS"
  date: "05-2025"
  title: "OoD Prediction for Emotion Transfer"
  description: "A transfer learning project using Task and Text Embeddings to predict model performance across different emotion classification datasets (Out-of-Distribution, OoD)."
  tools: "Python | DeBERTaV3-base | Task Embeddings | Transfer Learning"
  about: "The core challenge addressed is the difficulty of generalizing emotion classifiers across datasets due to varied labeling schemes. This project predicted the effectiveness of intermediate dataset transfer by building a regression model. The prediction variables were based on the similarity between datasets, quantified using class-conditional Task and Text Embeddings derived from gradient information, to determine which datasets serve as effective pre-training corpora."
  image: "/assets/images/atcs.png"
  url: "/pages/projects/ood-generalisation/"
  github-link: https://github.com/PirateEra/ood-generalization-transfer
  project_pdf_title: "Technical Report"
  project_pdf: "/assets/pdfs/ood-generalization.pdf"
  contributions:
    Transfer Learning and Model Prediction:
      - "Designed a pipeline to predict transfer performance (OoD Generalization) between emotion datasets without requiring full model evaluation."
      - "Fine-tuned a DeBERTaV3-base transformer encoder on 10 source emotion datasets in isolation to learn dataset-specific text representations."
      - "Developed a regression model to predict transferability loss based on dataset similarity metrics."
    Advanced Representation Learning:
      - "Implemented the construction of Task Embeddings using the squared gradient norm of the frozen encoder to capture dataset-specific structure."
      - "Created class-conditional representations for each emotion in each dataset, using both Task and Text Embeddings to quantify dataset similarity."
    Data Analysis and Visualization:
      - "Applied dimensionality reduction techniques to visualize the constructed Task Embeddings and discover structure within different emotional classification corpora."
      - "Addressed challenges from diverse theoretical frameworks and varied, non-overlapping label sets across multiple emotional classification corpora."
  media:
    - "/assets/images/atcs_poster.jpg"

- id: affiliaterobot
  date: "07-2023"
  title: "Affiliate Robot"
  description: "AI-driven web application that automates the generation of affiliate marketing articles using web scraping, dynamic prompting, and the OpenAI API."
  tools: "Python | PHP | OpenAI API | Web Scraping | HTML/CSS/JS"
  about: "Developed the core logic for Affiliaterobot.nl, a Minimum Viable Product (MVP) aimed at automating content creation for affiliate marketers. The system generated 'Top X' style articles by dynamically gathering product data via web scraping and using prompt engineering to synthesize the information into a structured, engaging article format. The site integrated user-specific affiliate links for revenue generation."
  image: "/assets/images/affiliate_robot_cover.png"
  url: "/pages/projects/affiliate-robot/"
  project_pdf_title: "Technical Report"
  project_pdf: "/assets/pdfs/affiliaterobot.pdf"
  contributions:
    AI and Dynamic Prompt Engineering:
      - "Authored the primary logic for the Article Generator, orchestrating the sequence from data acquisition to final LLM output."
      - "Implemented dynamic prompt creation using web-scraped data to guide the OpenAI API in generating contextually rich and accurate 'Top 10' style articles."
      - "Focused on prompt engineering to ensure the LLM output was structured correctly (e.g., using proper HTML) and aligned with the article's tone and format."
    Full-Stack Backend Integration:
      - "Developed a custom WordPress plugin in PHP to manage the entire back-end logic, including handling user input, and triggering the article generation process."
      - "Integrated the Python web scraping module with the PHP back-end to seamlessly pass scraped product data for prompt construction."
    Data Acquisition and Web Scraping:
      - "Designed and implemented the Python web scraping module targeting Bol.com to efficiently gather real-time data (product names, descriptions, prices, etc.) for dynamic content."
    Front-End Logic and MVP Development:
      - "Implemented the core article generator functionality using a combination of HTML, CSS, JavaScript, and PHP to structure the final article presentation on the front-end, supporting the full MVP requirements (account/login, options)."
  presentation_title: "Visual Interface Screenshots"
  presentation_folder: "/assets/slides/affiliaterobot/"

- id: roger
  title: "Robust AI-Generated Image Detection"
  date: "05-2025"
  description: "Developed ROGER, a robust, multi-modal model for AI-generated image detection that outperforms a state of the art model (SPAI) on augmented real-world images."
  tools: "Python | PyTorch | Selenium | Deep Learning"
  image: "/assets/images/roger_pipeline.png"
  url: "/pages/projects/roger/"
  project_pdf_title: "Technical Report"
  project_pdf: "/assets/pdfs/roger.pdf"
  github-link: https://github.com/PirateEra/ROGER
  contributions:
    Data Pipeline and Robustness Testing:
      - "Contributed to creating challenging datasets that simulate real-world image modifications to test model robustness."
      - "Specifically implemented the social media screenshot simulation dataset, using Selenium to dynamically inject images into a custom HTML template."
      - "Randomized numerous dynamic HTML elements (like/comment counts, usernames, captions) to ensure each generated screenshot was unique."
    Model Development (ROGER):
      - "Co-developed the ROGER (RObust AI-GEnerated image Recognizer) model to address the weaknesses of SPAI."
      - "Designed and implemented the integrated model approach, a multi-modal architecture combining three complementary AID models."
      - "Extracted and concatenated embeddings from SPAI (spectral), RINE (mid-level), and PatchCraft (texture) into a unified 768-dimensional feature vector."
      - "Trained the final MLP classification head (2-layer, 1536-unit) on the combined embeddings to produce a single, robust prediction."
    Performance Evaluation:
      - "Successfully reproduced the original SPAI paper's results, verifying its baseline performance and high reproducibility."
      - "Demonstrated that the created ROGER model significantly outperforms the baseline SPAI on all four challenging real-world datasets."
  media:
    - "/assets/images/roger_pipeline.png"

- id: medai
  date: "10-2025"
  title: "Improving 3D CT Organ Segmentation"
  description: "An AI for Medical Imaging project that improved 3D segmentation of thoracic organs by systematically addressing severe class imbalance and model noise."
  tools: "Python | PyTorch | Data Analysis | Loss Functions | Jupyter"
  about: "This project's goal was to improve upon a baseline ENet model for 3D segmentation of organs (Heart, Aorta, Esophagus, Trachea) in CT scans. The primary challenges were severe class imbalance and noisy predictions. I analyzed and implemented various techniques, a key component of this was a deep dive into custom loss functions and data analysis to mitigate imbalance."
  image: "/assets/images/ai4mi.png"
  url: "/pages/projects/medai/"
  github-link: https://github.com/PirateEra/ai4mi_project
  contributions:
    Data Analysis and Problem Identification:
      - "Analyzed the voxel and slice distributions for all 40 participants, identifying severe class imbalance as a core limitation."
      - "Quantified that background voxels made up 98.95% of the data, with rare classes like Esophagus (0.05%) and Trachea (0.03%) being vastly underrepresented."
    Loss Function Experimentation:
      - "Identified that the baseline cross-entropy loss struggled with rare classes."
      - "Researched and implemented alternative loss functions to address the imbalance, including pure Dice loss and various hybrid (Dice + Cross Entropy) losses."
      - "Analyzed the trade-offs of these losses, noting that Dice loss improved performance on rare classes by focusing on overall shape rather than individual voxels."
    Model Improvement and Evaluation:
      - "Contributed to the development of the final 'Best Model,' which integrated multiple improvements (2.5D, Multi-Window, SE blocks, NAdam)."
      - "The final model achieved major gains in rare class segmentation."
  presentation_title: "Impact of Loss Functions on Dice & HD95"
  presentation_folder: "/assets/images/projects/medai/"

- title: "Leren en Beslissen"
  description: "Random mock project"
  image: "/assets/images/projects/mock/mockimg.png"
  url: "/projects/mock project/"

- title: "Earth Shader Project"
  description: "Random mock project"
  image: "/assets/images/projects/mock/mockimg.png"
  url: "/projects/mock project/"

- title: "Raytracing Project"
  description: "Random mock project"
  image: "/assets/images/projects/mock/mockimg.png"
  url: "/projects/mock project/"

- title: "Bsc Thesis"
  description: "Random mock project"
  image: "/assets/images/projects/mock/mockimg.png"
  url: "/projects/mock project/"
